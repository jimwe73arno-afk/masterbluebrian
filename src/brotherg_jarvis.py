import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from jarvis_memory import JarvisMemory
from jarvis_prompts import get_system_prompt

# 1. é é¢åŸºç¤è¨­å®š
st.set_page_config(page_title="BrotherG Jarvis", page_icon="ğŸ§ ", layout="wide")
load_dotenv()

# 2. åˆå§‹åŒ– API Key
api_key = os.getenv("GEMINI_API_KEY")
if not api_key and "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]

if not api_key:
    st.error("âŒ æ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹æª¢æŸ¥ Secretsï¼")
    st.stop()

genai.configure(api_key=api_key)

# 3. æ™ºèƒ½æ¨¡å‹é¸æ“‡å™¨ (æ ¸å¿ƒä¿®å¾©ï¼šè‡ªå‹•å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹)
def get_working_model():
    # å„ªå…ˆé †åºï¼š2.0 (æœªä¾†) -> 1.5 Flash Latest (ç©©å®š) -> 1.5 Flash (åŸç‰ˆ) -> Pro (ä¿åº•)
    candidates = [
        "gemini-2.0-flash-exp",      # å˜—è©¦ 2025 å¹´æ–°æ¨¡å‹
        "gemini-1.5-flash-latest",   # å¼·åˆ¶æŒ‡å‘æœ€æ–°ç‰ˆ
        "gemini-1.5-flash",          # åŸæœ¬è¨­å®š
        "gemini-1.5-flash-001",      # æŒ‡å®šç‰ˆè™Ÿ
        "gemini-pro"                 # æœ€å¾Œä¿åº•
    ]
    
    # å¦‚æœå·²ç¶“æœ‰é¸å®šçš„å¯ç”¨æ¨¡å‹ï¼Œç›´æ¥å›å‚³
    if "valid_model_name" in st.session_state:
        return genai.GenerativeModel(st.session_state["valid_model_name"])

    # å¦å‰‡ï¼Œæ¸¬è©¦å“ªå€‹èƒ½ç”¨
    for model_name in candidates:
        try:
            model = genai.GenerativeModel(model_name)
            # è©¦æ‰“ä¸€å€‹æ¥µçŸ­çš„ç”¨ä¾‹ç¢ºèªå­˜æ´»
            model.generate_content("Hi") 
            st.session_state["valid_model_name"] = model_name
            # åœ¨å´é‚Šæ¬„å·å·å‘Šè¨´é–‹ç™¼è€…ç¾åœ¨ç”¨å“ªé¡†å¼•æ“
            with st.sidebar:
                st.caption(f"âœ… Engine: {model_name}")
            return model
        except Exception:
            continue
    
    st.error("âŒ æ‰€æœ‰ Gemini æ¨¡å‹éƒ½ç„¡æ³•é€£ç·šï¼Œè«‹æª¢æŸ¥ API Key é…é¡æˆ–å°ˆæ¡ˆæ¬Šé™ã€‚")
    st.stop()

# 4. åˆå§‹åŒ–è¨˜æ†¶èˆ‡æ¨¡å‹
@st.cache_resource
def init_memory():
    return JarvisMemory()

try:
    memory = init_memory()
    model = get_working_model() # ç²å–è‡ªå‹•æ¸¬è©¦éå¯ç”¨çš„æ¨¡å‹
except Exception as e:
    st.error(f"ğŸ”¥ ç³»çµ±å•Ÿå‹•å¤±æ•—: {e}")
    st.stop()

# 5. UI ä½ˆå±€
st.title("ğŸ§  BrotherG Jarvis - ç¬¬äºŒå¤§è…¦")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ”§ åŠŸèƒ½")
    if st.button("ğŸ—‘ï¸ æ¸…é™¤ç•¶å‰å°è©±"):
        st.session_state["messages"] = []
        st.rerun()

# 6. å°è©±é‚è¼¯
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# è™•ç†ç”¨æˆ¶è¼¸å…¥
if prompt := st.chat_input("èˆ‡ Jarvis å°è©±..."):
    # é¡¯ç¤ºç”¨æˆ¶è¨Šæ¯
    st.chat_message("user").markdown(prompt)
    st.session_state["messages"].append({"role": "user", "content": prompt})

    # ç”¢ç”Ÿ AI å›æ‡‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # æª¢ç´¢è¨˜æ†¶
            related_memories = memory.search_memories(prompt, limit=3)
            memory_text = "\n".join([f"- {m['content']}" for m in related_memories]) if related_memories else "ç„¡ç›¸é—œè¨˜æ†¶"

            # çµ„è£ Prompt
            system_prompt = get_system_prompt()
            full_prompt = f"""
            {system_prompt}
            
            [åƒè€ƒè¨˜æ†¶]:
            {memory_text}
            
            [ç”¨æˆ¶å•é¡Œ]:
            {prompt}
            """
            
            # å‘¼å«æ¨¡å‹
            response = model.generate_content(full_prompt)
            answer = response.text
            
            # é¡¯ç¤ºä¸¦å„²å­˜
            message_placeholder.markdown(answer)
            st.session_state["messages"].append({"role": "assistant", "content": answer})
            
            # å¯«å…¥æ–°è¨˜æ†¶ (Observations)
            memory.add_memory(f"User asked: {prompt} -> AI answered: {answer[:50]}...", category="conversation")
            
        except Exception as e:
            st.error(f"ç”Ÿæˆå¤±æ•—: {e}")
