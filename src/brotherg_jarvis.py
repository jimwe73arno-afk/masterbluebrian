import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from jarvis_memory import JarvisMemory
from jarvis_prompts import get_system_prompt

st.set_page_config(page_title="BrotherG Jarvis", page_icon="ğŸ§ ", layout="wide")
load_dotenv()

st.title("ğŸ§  BrotherG Jarvis - ç°¡ç´„ç‰ˆ")

# --- 1. API Key ---
api_key = os.getenv("GEMINI_API_KEY")
if not api_key and "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]

if not api_key:
    st.error("âŒ æ‰¾ä¸åˆ° API Key")
    st.stop()

genai.configure(api_key=api_key)

# --- 2. è¨˜æ†¶åº« ---
try:
    memory = JarvisMemory()
    with st.sidebar:
        st.success("âœ… Memory: Online")
except Exception as e:
    st.error(f"ğŸ”¥ Memory Error: {e}")
    st.stop()

# --- 3. æ¨¡å‹ (ç›´æ¥æŒ‡å®šï¼Œä¸è¼ªè©¢) ---
# ä½¿ç”¨æœ€é€šç”¨çš„æ¨™ç±¤ï¼Œç”± Google è‡ªå‹•åˆ†é…ç‰ˆæœ¬
TARGET_MODEL = "gemini-1.5-flash"

try:
    model = genai.GenerativeModel(TARGET_MODEL)
    # æ¸¬è©¦ä¸€ç™¼
    response = model.generate_content("Hi")
    with st.sidebar:
        st.info(f"ğŸš€ Engine: {TARGET_MODEL}")
except Exception as e:
    st.error(f"âŒ æ¨¡å‹å•Ÿå‹•å¤±æ•— (å¯èƒ½æ˜¯ API Key é¡åº¦ä¸è¶³æˆ–ç„¡æ•ˆ)ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
    st.stop()

# --- 4. å°è©± ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Master Blue è«‹æŒ‡ç¤º..."):
    st.chat_message("user").markdown(prompt)
    st.session_state["messages"].append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        msg_placeholder = st.empty()
        try:
            memories = memory.search_memories(prompt, limit=3)
            mem_text = "\n".join([f"- {m['content']}" for m in memories]) if memories else "ç„¡"
            
            sys_prompt = get_system_prompt()
            full_prompt = f"{sys_prompt}\n\n[åƒè€ƒè¨˜æ†¶]:\n{mem_text}\n\nUser: {prompt}"
            
            response = model.generate_content(full_prompt)
            answer = response.text
            
            msg_placeholder.markdown(answer)
            st.session_state["messages"].append({"role": "assistant", "content": answer})
            
            memory.add_memory(f"Q: {prompt} | A: {answer[:30]}...", category="chat")
        except Exception as e:
            st.error(f"ç”Ÿæˆå¤±æ•—: {e}")
